{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9wUlvMnxHqg"
   },
   "source": [
    "# Neural Network - Bonus: Data Detective\n",
    "\n",
    "This notebook is not mandatory - feel free to do it if you are looking for some more experience, and want to detect a pitfall that typically occurrs at least once to every data scientist.\n",
    "\n",
    "The notebook is a variation of project 3 on regression for the `diamonds` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ni_i_5c0PUn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGaFpezoEZGg"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('diamonds.csv')\n",
    "\n",
    "# Define X by dropping the 'price' column\n",
    "X = data.drop('price', axis=1)\n",
    "\n",
    "# Keep only numerical columns in X\n",
    "X = X.select_dtypes(include=['number'])\n",
    "\n",
    "# Define y as the 'price' column\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFFXuhT_LWCY"
   },
   "source": [
    "### Train Test split\n",
    "**Exercise:** Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "U_aimKQl6_Qk",
    "outputId": "f29c1035-621a-4def-afd5-f28eda0d885b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Hint:\n",
    "    1) Utilize the train_test_split function from the sklearn.model_selection module to split the dataset into training and testing sets.\n",
    "    2) Set the test_size parameter to 0.2 to allocate 20% of the data for testing.\n",
    "    3) Use random_state=1 to ensure the split is reproducible.\n",
    "'''\n",
    "\n",
    "# X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V5L7cN0LZYf"
   },
   "source": [
    "### Transformation\n",
    "**Exercise:** The next step is to scale the data using a `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "nnoe4vuX7SyA",
    "outputId": "b2e21295-4979-4faa-fe1e-ee99c64ed835"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Hint:\n",
    "      1) To standardize the features, use the StandardScaler class from the sklearn.preprocessing module.\n",
    "      2) Create an instance of StandardScaler and use the fit_transform() method on the training data to compute and apply the scaling.\n",
    "      3) Use the transform() method to apply the same scaling to the test data, ensuring consistency across both datasets.\n",
    "'''\n",
    "\n",
    "# Initialize the scaler\n",
    "# ...\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "# ...\n",
    "# X_train_scaled = ...\n",
    "# X_test_scaled = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLlXo_sx9lit"
   },
   "source": [
    "### Neural network architecture\n",
    "\n",
    "It is time to define the neural network model using TensorFlow's Keras API to perform regression on the diamond dataset.\n",
    "\n",
    "* **Input Layer:**\n",
    "A dense layer with ***50*** neurons and the *ReLU* activation function. The input_shape is set to the number of features in `X_train`, which allows the model to know the shape of the input data.\n",
    "* **Hidden Layer 1:**\n",
    "A second dense layer with ***75*** neurons and the ReLU activation function.\n",
    "* **Hidden layer 2:**\n",
    "A third dense layer with ***30*** neurons and the ReLU activation function.\n",
    "* **Output Layer:**\n",
    "A dense layer with a **single neuron** (*no activation function*) since this is a regression problem and we want to predict a continuous value (`price` of the diamond).\n",
    "\n",
    "**Exercise:** Using tensorflow and keras, define a neural network according to these specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "WWnF3meYKdH2",
    "outputId": "fe594908-35a8-4898-8bbf-51e9732c9a6e"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Hint:\n",
    "  1) Use tf.keras.Sequential() to create a Sequential model. This allows you to add layers to the model one by one.\n",
    "  2) Add the first Dense layer with 100 neurons and activation='relu'.\n",
    "  3) Add a hidden Dense layer with 50 neurons and activation='relu'.\n",
    "  4) Add a final Dense layer with 1 neuron. Since it's a regression task, there is no activation function for the output layer..\n",
    "'''\n",
    "\n",
    "# model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "jsCnbx8QlEG6",
    "outputId": "d174d9c0-fe50-4627-cf7c-3c4d463d05cd"
   },
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "792uwMN4KnzA"
   },
   "source": [
    "### Model Training\n",
    "\n",
    "Now that we have defined the model, we can prepare the code to train it.\n",
    "\n",
    "**Exercise:** Implement the necessary steps to train the model. You can check one of the notebooks from the second block to get some inspiration. What are key parameters you have to set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "zvYr-sYn7GWp",
    "outputId": "db676064-998d-4a15-a53b-e82e931206b8"
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RhXpwDwNx_Y"
   },
   "source": [
    "### Model Evaluation\n",
    "Now we are ready to evaluate the model. \n",
    "\n",
    "**Exercise:** predict the prices of both the training and the test data. Evaluate the performance using the MSE and the R2-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF8Fgw6ycFzl"
   },
   "source": [
    "**Exercise:** Compare this result with the result you obtained in the 3rd project (if you did the regression project).\n",
    "\n",
    "Would you trust the result?\n",
    "\n",
    "Let us run a little experiment. Let's look at how we loaded the data - we used the following command to do so:\n",
    "\n",
    "`data = pd.read_csv('diamonds.csv')`\n",
    "\n",
    "Now, replace that line by\n",
    "\n",
    "`data = pd.read_csv('diamonds.csv', index_col=0)`\n",
    "\n",
    "and run the notebook again. \n",
    "\n",
    "What has happened? Why did this small change make such a big difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
