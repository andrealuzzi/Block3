{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and EDA in Python: Car Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you are working with real-world data, data preparation is the first step.\n",
    "It is typically interleaved with exploratory data analysis (EDA). The two activities require and foster understanding of the data (including the measurement process) as well as the objects under study. This is an essiential basis for any data-driven hypotheses and models.\n",
    "\n",
    "We will learn about explorative data analysis using the example of car data. We want to find out whether we can identify relationships between the attributes of cars out of the given dataset.\n",
    "\n",
    "This notebook is adapted from an opensource notebook that is available here: `https://github.com/Tanu-N-Prabhu/Python/blob/master/Exploratory%20Data%20Analysis/%20Exploratory_data_Analysis_1.ipynb.`\n",
    "The data we will use is taken from `https://www.kaggle.com/CooperUnion/cardataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Importing the required python-libraries \n",
    "As we have seen in previous notebooks, libraries contain functionalities that go above the standard python implementation. These can be very useful for our tasks.\n",
    "\n",
    "`pandas` and `numpy` contain datatypes and data structures that are used often in machine learning tasks, such as e.g. *data frames*. `seaborn` and `matplotlib` are popular libraries used to visualize data. We have used `pandas`, `seaborn`, and `matplotlib` previously and will now learn about some methods contained in `numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns                     \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline     \n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, root_mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "First we start by loading the data. To get an impression of what type of data we are working with, we will look at the first few entries and generate a description of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv('car_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the dataset, let's print some information about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What do we learn from this result? What do the different datatypes mean (`Dtype`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to take a look at the actual data, using `df.head(5)`, and `df.tail(5)` that you have used before, we will get the first, and the last 5 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 5 rows\n",
    "car_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the last 5 rows\n",
    "car_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing unnecessary data\n",
    "We won't need all attributes in the data analysis. Therefore, it makes sense to leave some out in advance. This step makes it easier to get (and keep) an overview of the data.\n",
    "\n",
    "***Please note***: When working with larger datasets, it is likely that a large number of attributes have to be left out. It might also make sense to only work with a subset of the data. However, it is important not to leave out too much data in advance. As we are working in an explorative manner, we don't know what attributes we might need in later steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's remove a couple of attributes that don't seem important and print the first and last 5 rows again. \n",
    "car_df = car_df.drop(columns=['Market Category', 'Vehicle Style', 'Popularity', 'Vehicle Size'])\n",
    "car_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What do you notice when looking at the results? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "Most real word data has to be cleaned before we can use it for data analysis. For example, some datasets may contain duplicates, as we have just seen in the example above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the shape of the dataset.\n",
    "car_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates\n",
    "Duplicates can appear in our data for many reasons, such as measurements that were repeated, or - as in our case - from removing attributes that would have made the data differ. The meaning of duplicates strongly depends on the application, they don't always have to be removed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Can you think of reasons why duplicate rows in a dataset might be bad for machine learning usecases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a new dataframe and printing the number of rows that are duplicated\n",
    "duplicate_rows_df = car_df[car_df.duplicated()]\n",
    "print('number of duplicate rows: ', duplicate_rows_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in the correlation between the single attributes of cars, we don't need duplicates. Therefore, we want to remove them using the `drop_duplicates()` method. Note how the shape of the car dataframe changed compared to before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = car_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformating values\n",
    "In the USA, the consumption of cars is measured in MPG (Miles per Gallon). In Switzerland however, we usually measure the amount of gas consumed per 100 km. Therefore, we want to change the data we received, to reflect swiss standards. As in the provided dataset, we want to separate the consumption on highways from the consumption in cities. \n",
    "For this purpose, we will define a **function** `mpg_to_lpro100km`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpg_to_lpro100km(mpg):\n",
    "    # converts miles per gallon to liters per 100 km\n",
    "    return (100 * 3.785411784) / (mpg * 1.609344)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply this function to both attributes (`highway MPG` and `city mpg`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['consumption_city'] = mpg_to_lpro100km(car_df['city mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Change the above line to also transform the attribute `highway MPG` into swiss standards. Save your result in a new attribute called `consumption_highway`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these lines of code don't produce an output. Instead, the result is saved in a new column in a dataframe. Therefore, our `car_df` dataframe now has two new columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: write code to remove the columns containing the MPG. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming of Columns \n",
    "As a last preparation step, we want to change the names of some of the attributes. The names are too long and we would like them to be more concise. We use the function `rename` to do so - it takes as argument `columns` a dictionary of the form `{<old_name1>: <new_name1>, <old_name2>: <new_name2>, ...}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = car_df.rename(columns={'Make': 'Brand',\n",
    "                                'Engine Fuel Type': 'F_type',\n",
    "                                'Engine HP': 'HP',\n",
    "                                'Engine Cylinders': 'Cylinder',\n",
    "                                'Driven_Wheels': 'Wheels',\n",
    "                                'Number of Doors': 'Doors',\n",
    "                                'Transmission Type': 'T_type',\n",
    "                                'MSRP': 'Price'\n",
    "                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Non-Numerical Attributes\n",
    "We also notice, that the dataset contains values that are not numerical. If we want to work with these attributes, we need to convert these non numerical values into numerical values.\n",
    "To do this, we create \"dummy\"-values to represent the different types of values. \n",
    "Let's do this for the attribute `F_type`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first look at the different types of fuel our cars use: \n",
    "values = car_df['F_type'].unique()\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 10 different types of fuel (excluding nan, which we will look at in more detail later). \n",
    "We will now use the function .get_dummies() to get dummy values that help us distinguish the different types of fuel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_dummies = pd.get_dummies(car_df, columns=['F_type'])\n",
    " \n",
    "# Let's take a look at what this new dataframe looks like: \n",
    "\n",
    "print(fuel_dummies.count())\n",
    "fuel_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "What can we learn about how this method distinguishes the different types of fuel, by looking at the printed new dataframe `fuel_dummies` above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "Inspect the other datatypes and transform the attributes that are not numerical, such that there are only numerical values left. The last lines of code transform boolean values to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brand_dummies = ...\n",
    "# model_dummies = ...\n",
    "# t_dummies = ...\n",
    "# wheels_dummies = ...\n",
    "\n",
    "# for the Boolean values to be transformed to numerical values, we use the method .astype(int) \n",
    "# all_dummies = wheels_dummies.dropna().astype(int)\n",
    "# all_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stick to the original dataframe `car_df` for the rest of the evaluation, but we will need the dataframe `all_dummies`for training later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a look at the data\n",
    "So far we have worked on entire rows or columns of the dataset. Now we want to check out the values of single attributes (or columns) in more detail. \n",
    "\n",
    "### How many records contain values?\n",
    "First, let's check how many of the records contain data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data we have 11099 rows left. The attributes `Brand`, `Model`, `Year` are present in every row. However, three cars have no information about the `F_type`, and 68 cars are missing entries on the horse power (`HP`). Furthermore, 30 cars are missing information about the cylinders.  \n",
    "\n",
    "**Exercise**: Do you think there might be a reason why some rows lack data about certain attributes? \n",
    "*Domain knowledge*, in this case about cars, is very important to formulate hypotheses in practice. These can then be verified using the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values are handled in a special way in most programming languages. In Python, numerical values that are missing are denoted by `NaN` (`np.NaN`), which stands for *Not a Number*. Using the method `car_df.count()` we count the rows for each column, only if there are values in that row. The rows for which the `F_type` value is missing are left out of this count. We can identify these empty entries using the `pd.isna(...) ` function. It returns a Boolean value (`True` if the value is `NaN`and `False` otherwise) for each entry, which we can use after to make logical indices in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df[pd.isna(car_df['F_type'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often do different values appear?\n",
    "Next we want to see how often the different types of fuel are present in the data. We use the `.groupby()` method from `pandas`, which is grouping rows of a dataframe by one or more keys (columns). `car_df.groupby('F_type')` will thus, for every values of `car_df['F_type']`, give us a group with all cars that run on this fuel type. On the resulting groups, we then run `size` to count the elements (i.e., the cars) in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby('F_type').size()\n",
    "# Since we want to see the amount of cars using the different types of fuel, we use .size()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine the combination of `F_type` and amount of `Cylinder`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['F_type', 'Cylinder']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Pay attention to the two outputs concerning electric cars above. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw above, that there is something happening with the electric cars, that makes some not be included in the grouped output. So let's look at the list of all electric cars. For the sake of readability, usually only a subset of the rows of data frames are printed in Jupyter Notebooks. The maximal number of printed cells can be controlled through the `display.max_rows` option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the current value of max_rows:\n",
    "pd.get_option('display.max_rows') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the result is less than the amount of entries we have, \n",
    "# let's change the value of max_rows to: \n",
    "pd.set_option('display.max_rows', car_df.shape[0]+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we print all cars from this dataframe that use the electric fuel type\n",
    "car_df[car_df['F_type']=='electric']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Take a good look at the result above, especially the count of `Cylinder`. Do you find an answer to the question that we had before, about electric cars?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "As we saw above, some values can be missing (`NaN`), or a special value can be attributed to them (0 in this case) - 0 cylinders does not make sense for cars with a combustion engine! \n",
    "\n",
    "It is also important to identify so called *outliers*. As we have seen in previous notebooks, outliers are values that are unproportionally low or high, compared to the other values in that category, or *special* in some other aspect. For instance in this example, the price and the horse power of sports cars is a lot higher than that of the regular cars. \n",
    "Let's take a look at the data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal and Minimal entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the following method to determine the lowest price of a car in our database. \n",
    "np.min(car_df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the following method to determine the highest price of a car in our database. \n",
    "np.max(car_df['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have a huge range of prices in this dataset, from 2000 to over 2 million Dollars! It seems unlikely that the same dependencies (e.g., between price and horse power) are valid across the entire range - we will keep this in mind when building a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles\n",
    "Another interesting indicator are the percentiles, that we have also already encountered in previous exercises. The x%-percentile value measures the price that is larger then  x% of the values in our dataset are. For example, let's look at the 50% percentile of the car prices in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(car_df['Price'], 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, 50 % (aka. half) of the cars in our dataset cost less than 30850$ and the other half cost more. Here, 50 is called the *percentile rank*, and 30850.0 is the *percentile value*.\n",
    "\n",
    "Let's compute the values for some more percentiles ranks.  \n",
    "By passing an array of values to this function, we will get an array of results, i.e., we will get the percentile value of each of these percentile ranks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(car_df['Price'], [ 5, 10, 25, 75, 90, 95 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show: \n",
    "* The 25%-Percentile - which is also called **first quartile** - of the car prices is 21'835 USD. This means that the cheapest quarter of cars cost less than 21'835 USD.\n",
    "* The 75%-Percentile, also called **third quartile** of car prices, is 43'247.50 USD; hence three fourth of the cars in our dataset cost at most that much. \n",
    "* The \"middle half\" of the cars therefore have a price between  21'835USD and 43'247.50 USD.\n",
    "* The **inter-Quartile-Difference** (IQD) is 43'247.50 USD-21'835 USD = 21'412.5 USD. The IQD is an important measure for the **distribution** in the middle areas.\n",
    "* At the top the prices appear to diverge: The 95%-Percentile is 113'400 USD. The 5% most expensive cars all cost more than that value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise***: How much do the 1% most expensive cars of our dataset cost? Compute and comment on the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First visualisations\n",
    "We now want to generate some plots, in the same way as we have done in previous notebooks: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot\n",
    "Boxplots allow us to visualize the distribution of the data and some of the statistics that we have calculated above. \n",
    "        \n",
    "***Note***: Boxplots can be parametrised in different ways, especially concering the whiskers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, main_ax = plt.subplots(figsize=(15,8))\n",
    "main_ax.boxplot(car_df['Price'], vert=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers, which are the very expensive cars in this case, affect the visualisation: the x-axis is showing all values. Therefore, the price range that is relevant for most people looking to buy a car is squished to a small area.  \n",
    "Using the method `main_ax.set_xlim(0, 250000)` that we import from the Axis class, we can reduce the price range of the x-axis. Here we reduce it to the range of 0 until 250\\'000 USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, main_ax = plt.subplots(figsize=(15,8))\n",
    "main_ax.boxplot(car_df['Price'], vert=False)\n",
    "main_ax.set_xlim(0, 250000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plot\n",
    "A bar plot is used to visualize how often each unique value in a dataset appears.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['Brand'].value_counts().nlargest(40).plot(kind='bar', figsize=(15,8))\n",
    "plt.title('Amount of cars per car brand')\n",
    "plt.ylabel('Amount of cars')\n",
    "plt.xlabel('Brand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "A histogram looks very similar to a bar plot, but histograms are based on **continuous** data. These continuous values are divided into intervals when the plot is generated and then the amount of entries per interval is counted and plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,8))\n",
    "plt.hist(x=car_df['Price'])\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Amount of cars')\n",
    "plt.title('Amount of cars per price range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python, and in this case `matplotlib`, is choosing the x- and the y- axis scale such that all values can be shown. Since our dataset contains a small number of very expensive cars, most other cars end up in the same category, on the left. Therefore, we will generate this plot again and only include cars that have a price below 250\\'000 USD. We are also setting `bins` to 25, which means that we want to divide the price range into 25 intervals of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,8))\n",
    "plt.hist(x=car_df['Price'][ car_df['Price']<250000 ], bins=25)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Amount of cars')\n",
    "plt.title('Amount of cars per price range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Heatmaps\n",
    "Correlation (which we have already seen in other notebooks) is a statistical measure that quantifies the relationship between variables. Correlation values range between -1 and +1.\n",
    "\n",
    "* A correlation of +1 between two variables indicates that their values move in the same direction. For example, \"The more we have of x, the more we have of y.\" A real-world example is the relationship between the distance you drive and the amount of gas you consume — the farther you drive, the more gas you use.\n",
    "\n",
    "* A correlation of -1 between two variables indicates that their values move in opposite directions. For example, \"The more we have of x, the less we have of y.\" A real-world example is the relationship between the distance driven and the amount of gas left in your tank — the farther you drive, the less gas remains (until you refill the tank).\n",
    "\n",
    "* A correlation of 0 between two variables means they are independent of each other. For instance, the amount of gas your car consumes is not correlated with the length of your hair.\n",
    "\n",
    "The strength of the correlation (how close the value is to -1 or +1) indicates the magnitude of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the concrete example of the car dataset. We will use the method `.corr()` to calculate the correlation between the variables. We should first check the different datatypes of the values we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to include the columns that contain numerical values: \n",
    "numeric_df = car_df.select_dtypes(include=[float, int])\n",
    "c = numeric_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in previous exercises, we can visualize the correlation in a heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.heatmap(c, cmap='plasma', fmt=\".2f\",vmin=-1, vmax=1, annot=True)\n",
    "plt.gca().set_title('Heatmap of the correlation between all cars.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we looked at outliers earlier - there are some cars, that are extremely expensive. \n",
    "But in the evaluation above, we have used all cars. \n",
    "Let's repeat this evaluation using only cars that cost less than **50\\'000 USD**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "c_normal = numeric_df[ numeric_df['Price']<50000 ].corr()\n",
    "sns.heatmap(c_normal, cmap='plasma', vmin=-1, vmax=1, annot=True)\n",
    "plt.gca().set_title('Heatmap of the correlations for Cars that cost below 50\\'000 USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What are the correlations for very expensive cars (Price above 250\\'000 USD)? Create a third plot, by adapting the code above. What do you notice? Where are the biggest differences between all three plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots\n",
    "The correlation and the corresponding Heatmap are very useful tools to visualize the entire dataset (that is why this is called *summary statistics*). However, we loose the information about single datapoints, and outliers can have a huge influence on the results of the evaluation. \n",
    "\n",
    "When we make scatterplots we choose two attributes, which we use as the values for the x- and y-axis, and represent every single datapoint. This gives us a more detailed view on the data. \n",
    "As an example we use the correlation between `HP` and `Price`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(car_df['HP'], car_df['Price'])\n",
    "plt.title('Scatterplot between HP and Price')\n",
    "ax.set_xlabel('Power in [HP]')\n",
    "ax.set_ylabel('Price in [US-$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this representation we can see the outliers very well: there are three cars with around 1000 PS, and two cars with a price of over 1 Mio USD. \n",
    "\n",
    "We will make a second plot to only look at cars that cost less than 1 Mio USD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_u1M = car_df[ car_df['Price']<1000000 ]\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(cars_u1M['HP'], cars_u1M['Price'])\n",
    "plt.title('Scatterplot between HP and price, price below 1 Mio USD')\n",
    "ax.set_xlabel('Motor power in [HP]')\n",
    "ax.set_ylabel('Price in [USD]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want another plot with all cars that cost less than 50\\'000 USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_u50k = car_df[ car_df['Price']<50000 ]\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(cars_u50k['HP'], cars_u50k['Price'])\n",
    "plt.title('Scatterplot between HP und Price, price below 50\\'000 USD')\n",
    "ax.set_xlabel('Power in [HP]')\n",
    "ax.set_ylabel('Price in [USD]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for cars with a price above 10\\'000 USD, the price increases with increasing horse power. That corresponds to the observation we got in the correlation matrix - for the relationship between `HP`, and `Price` the computed correlation was at 0.66. \n",
    "\n",
    "Therefore, we can formulate the following **hypothesis**: For cars with a price between 10\\'000 USD and 50\\'000 USD, there is a linear dependency between the price and the motorpower in HP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**: \n",
    "* What further relationships can we see in the data? Play around with the plots and make scatterplots for different combinations of car attributes. You can for instance be inspired by the correlation matrix. But, even if the correlation is 0, can you find some explanation in part of the data? \n",
    "Identify at least two further hypotheses for a correlation.\n",
    "* Looking at the plots above (and possibly other ones you have generated), where do you assume relevant differences in the underlying structure of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "We will now implement regression models, following the same approach we used in the previous notebooks. \n",
    "\n",
    "### Auxiliary Functions\n",
    "We first define 3 auxiliary functions which take over functionality we will use repeadedly to compare different models:\n",
    "\n",
    "* apply_eval_model: applies a model to a given dataset and evaluates the performance\n",
    "* train_apply_eval_model: trains a **scikit-learn model** (e.g., linear regression, etc.) on a given dataset, and evaluates the performance on the training and test set\n",
    "* train_apply_eval_NN_model: trains a **neural network model implemented in tensorflow** on a given dataset, and evaluates the performance on the training and test set\n",
    "You do not need to understand these functions in detail, but make sure to use the appropriate function, as you might get errors otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_eval_model(model, X, y_true, model_name, do_print=True):\n",
    "    \"\"\"\n",
    "    Function to evaluate a given model on a feature data frame and compute several performance metrics.\n",
    "    The results are returned as a data frame and optionally printed out.\n",
    "\n",
    "    Arguments:\n",
    "    model - the model to be evaluated\n",
    "    X - a data frame containing the predictors\n",
    "    y_true - the true target values, used for the performance assessment\n",
    "    model_name - name of the model (will be added to the result data frame)\n",
    "    do_print - optional argument to indicate whether the results should be printed\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    if do_print:\n",
    "        print('r2-Score: ' + str(r2_score(y_true, y_pred)))\n",
    "        print('MSE: ' + str(mean_squared_error(y_true, y_pred)))\n",
    "        print('RMSE: ' + str(root_mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "    if len(model_name)>0:\n",
    "        df = pd.DataFrame({'model_name': model_name,\n",
    "                           'r2_score': r2_score(y_true, y_pred),\n",
    "                           'MSE': mean_squared_error(y_true, y_pred),\n",
    "                           'MAE': mean_absolute_error(y_true, y_pred),\n",
    "                           'RMS': root_mean_squared_error(y_true, y_pred)},\n",
    "                           index=[model_name])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_apply_eval_model(model, X_train, y_train, X_val, y_val, model_name='model', num_epochs=20, batch_size=16, do_print=True):\n",
    "    \"\"\"\n",
    "    Train a given scikit-learn model on a training data set, and evaluate it on both the training and validation data.\n",
    "\n",
    "    Arguments:\n",
    "    model - the model to be evaluated\n",
    "    X_train - the training predictors\n",
    "    y_train - the true labels of the training data set\n",
    "    X_val - the predictors of the validation data set\n",
    "    y_val - the true labels of the validation data set\n",
    "    model_name - name of the model (will be added to the result data frame)\n",
    "    do_print - optional argument to indicate whether the results should be printed\n",
    "    \"\"\"\n",
    "\n",
    "    n_val = X_val.shape[0]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if do_print:\n",
    "        print('Evaluation on Training Data:')\n",
    "    res_train = apply_eval_model(model, X_train, y_train, model_name, do_print=do_print)\n",
    "    res_train['dataset'] = 'train'\n",
    "\n",
    "    if n_val>0:\n",
    "        if do_print:\n",
    "            print('\\nEvaluation on Validation Data:')\n",
    "        res_val = apply_eval_model(model, X_val, y_val, model_name, do_print=do_print)\n",
    "        res_val['dataset'] = 'validation'\n",
    "\n",
    "        return pd.concat([res_train, res_val])\n",
    "    else:\n",
    "        return res_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_apply_eval_NN_model(model, X_train, y_train, X_val, y_val, model_name='model', num_epochs=20, batch_size=16, do_print=True):\n",
    "    \"\"\"\n",
    "    Train a given neural network model on a training data set, and evaluate it on both the training and validation data.\n",
    "\n",
    "    Arguments:\n",
    "    model - the model to be evaluated\n",
    "    X_train - the training predictors\n",
    "    y_train - the true labels of the training data set\n",
    "    X_val - the predictors of the validation data set\n",
    "    y_val - the true labels of the validation data set\n",
    "    model_name - name of the model (will be added to the result data frame)\n",
    "    do_print - optional argument to indicate whether the results should be printed\n",
    "    \"\"\"\n",
    "\n",
    "    n_val = X_val.shape[0]\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error', 'r2_score']\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    if do_print:\n",
    "        print('Evaluation on Training Data:')\n",
    "    res_train = apply_eval_model(model, X_train, y_train, model_name, do_print=do_print)\n",
    "    res_train['dataset'] = 'train'\n",
    "\n",
    "    if n_val>0:\n",
    "        if do_print:\n",
    "            print('\\nEvaluation on Validation Data:')\n",
    "        res_val = apply_eval_model(model, X_val, y_val, model_name, do_print=do_print)\n",
    "        res_val['dataset'] = 'validation'\n",
    "\n",
    "        return history, pd.concat([res_train, res_val])\n",
    "    else:\n",
    "        return history, res_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Sports Cars and Regular Cars\n",
    "Based on our earlier analysis, we noticed that the correlation between car prices and other attributes differs between sports cars and regular cars. To test if separating the data improves accuracy, we’ll split the dataset into two groups and train models for each separately. We’ll use horsepower (HP) as the defining factor, categorizing cars with more than 400 HP as sports cars and the rest as regular cars. We will then use 3 different models to predict the price from the horsepowers.\n",
    "\n",
    "For clarity, we use the following naming convention:\n",
    "* `_all` is used to denote datasets that contain all cars. For example, `X_all`, `X_all_train`, etc. `X_all_test` are the features for the setting where we have one model for all cars.\n",
    "* `_reg` is used to denote \"regular\" cars, i.e., cars with less than 400 HP.\n",
    "* `_sport` is used to denote sport cars.\n",
    "\n",
    "Furthermore, to avoid overfitting, we will not use the `Brand` and `Model` information, i.e., for this part, we only consider columns that do not contain `Brand` or `Model` in the name. This is what `cols_2use` is ensuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2use = [c for c in all_dummies.columns if (('Brand' not in c) and ('Model' not in c))]\n",
    "cols_2use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cars:\n",
    "numeric_df = all_dummies[cols_2use].dropna()\n",
    "#numeric_df\n",
    "y_all = numeric_df['Price']\n",
    "X_all = numeric_df.drop(['Price'], axis=1)\n",
    "\n",
    "# Now we split the data into training and validation sets\n",
    "X_all_train, X_all_val, y_all_train, y_all_val = train_test_split(X_all, y_all, test_size=0.2, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_all_train_scaled = scaler.fit_transform(X_all_train)\n",
    "X_all_val_scaled = scaler.transform(X_all_val)\n",
    "\n",
    "y_all_train = np.array(y_all_train)\n",
    "y_all_val = np.array(y_all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'regular' cars with less than 400 HP\n",
    "numeric_df = all_dummies[cols_2use].dropna()\n",
    "regularCars = numeric_df[numeric_df['HP'] < 400]\n",
    "\n",
    "# let's define a model for the regular cars: \n",
    "y_regular = regularCars['Price']\n",
    "X_regular = regularCars.drop(['Price'], axis=1)\n",
    "\n",
    "X_reg_train, X_reg_val, y_reg_train, y_reg_val = train_test_split(X_regular, y_regular, test_size=0.2, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_reg_train_scaled = scaler.fit_transform(X_reg_train)\n",
    "X_reg_val_scaled = scaler.transform(X_reg_val)\n",
    "\n",
    "y_reg_train = np.array(y_reg_train)\n",
    "y_reg_val = np.array(y_reg_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Define the corresponding datasets for sport cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining, Training and Evaluating the Model: Linear Regression\n",
    "We want to predict the price of a car, given the other features. \n",
    "We are using the data with dummy features we generated previously, as it contains all important features in a numerical form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cars:\n",
    "model_lr_all = LinearRegression()\n",
    "\n",
    "model_lr_all_result = train_apply_eval_model(model_lr_all, X_all_train_scaled, y_all_train, X_all_val_scaled, y_all_val,\n",
    "                                             model_name='lin.reg., all cars')\n",
    "model_lr_all_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Train and evaluate two separate models for the regular and the sports cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular cars:\n",
    "# model_lr_reg = ...\n",
    "\n",
    "# model_lr_reg_result = ...\n",
    "# model_lr_reg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sport cars:\n",
    "# model_lr_sport = ...\n",
    "\n",
    "# model_lr_sport_result =\n",
    "# model_lr_sport_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the performance of the individual results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all results:\n",
    "results_lr = pd.concat([model_lr_all_result, model_lr_reg_result, model_lr_sport_result])\n",
    "\n",
    "# Plotting the results\n",
    "metrics =['r2_score', 'RMS']\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    sns.barplot(data=results_lr, y='model_name', x=metric, hue='dataset', ax=axs[i])\n",
    "    axs[i].legend()\n",
    "    axs[i].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Interpret the results. What benefit can we draw from splitting the cars into regular and sport cars?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Can you spot any further outliers in the set of regular cars? Make sure that you follow a principled approach and don't just get rid of examples (i.e., cars) that your model fails to accurately predict!\n",
    "\n",
    "**Optional Exercise:** Modify the code above to filter out these further outliers, and run the model comparison again. How does the performance evolve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optinal Exercise:** Re-run the above comparison using a neural network regression model. Use the functions provided above to fit and evaluate the models. Follow the same structure and plot the results at the end. Comment on your findings - in particular, do the findings we have obtained for linear regression also hold for a neural network model?\n",
    "\n",
    "***Hint:*** You can use `model2 = tf.keras.models.clone_model(model1)` to get a copy of `model1` and save it as `model2`. The new model `model2` will have the exact same structure (i.e., same type, width and number of layers), but can be trained separately based on a different dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
