{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbqe30DaMFJE"
   },
   "source": [
    "# Project 5: Data Science & Machine Learning on Votings of the Swiss National Council\n",
    "\n",
    "In project 5, we will analyze the voting behavior of the \"Nationalrat\" of the Swiss parliament in a number of ways. The project consists of 3 different files:\n",
    "\n",
    "* Data Preparation (this notebook): Prepare the data for the other two notebooks.\n",
    "* Predictions: Predict the voting behavior of individual members or the entire council.\n",
    "* Unsupervised: Find lower-dimensional representations of the voting behavior and groups of members of parliament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "In this notebook, we clean and reformat the raw data on the votings of the national council analysis such that it will be ready for the other two notebooks. \n",
    "\n",
    "In most of the project (i.e., all except one part of the unsupervised learning notebook), we will consider the voting proposals as observational units, and the votes by the members of parliament as variables. With this understanding, additional information about the proposals are also variables added as a column. However, in a strict interpretation, this might not be fully compliant with the ideas of a tidy dataset, but it serves purpose as a joint basis for the supervised and unsupervised learning notebook. In the supervised learning notebook, we will in fact further transform the notebook into a fully tidy representation.\n",
    "\n",
    "**You have to run this notebook before you can work on the other two.**\n",
    "\n",
    "**To avoid potential issues with memory limitations (which might result in the kernel dying), we recomment that you click \"Close and Shut Down Notebooks\" (in the \"File\" tab) before you start another notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data\n",
    "The voting behavior for every member of parliament as well as some information about the subjects of the vote are publicly available from https://www.parlament.ch/de/ratsbetrieb/abstimmungen/abstimmung-nr-xls (though only in German, French and Italian). We have downloaded the data for the summer sessions of the last four years. We will run the notebook on the latest data (i.e., from the year 2024) - but you are of course free to change to a different year, and you can also download further data files, namely from earlier years or from the council of states (\"Ständerat\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJxxIB4yrC8m",
    "outputId": "d9c5530b-311d-45ba-8738-d5aa2818cc80"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is given as Excel sheets; we load it using `read_excel` from the `pandas` package. It might be worth to open the file in Excel to see how it's structured.\n",
    "\n",
    "We see that the first two rows have a different format than the rest and do not contain substantial information. We therefore skip these two rows to avoid problems with the parsing of the file content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HGSEGcmrJCj"
   },
   "outputs": [],
   "source": [
    "file_path = 'Abstimmungen_NR_2024SS_DE.xlsx'\n",
    "df_votings_raw = pd.read_excel(file_path, header = None, skiprows=range(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1r5okBNuHX9"
   },
   "source": [
    "## Format Headers and Columns\n",
    "Let's have a look at the data we have just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votings_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votings_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pvNtybaNg6I"
   },
   "source": [
    "### Format Headers \n",
    "The data is formatted such that the actual voting data only starts at the line 8, with line 7 containing the column titles about the proposals. On the right of the information about the voting proposals, there is one column per member of parliament, containing some general information about that member (name, parliamentary group, canton, date of birth, date of swearing in).\n",
    "\n",
    "In a transaction system (OLTP), one would have (at least) two different tables, one for the votes and one for the members of parliament. However, for now, we just combine the pieces of information on the members of parliament into one string that we will use as header. This is done in the next cell (you don't have to understand the details of this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_rows = df_votings_raw.iloc[:8]\n",
    "combined_headers = header_rows.apply(lambda x: x.ffill()).apply(lambda x: ' | '.join(x.dropna().astype(str)), axis=0)\n",
    "print(combined_headers[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a data frame `df_votings` from the actual data items (i.e., the rows 8 and onwards) and use these combined strings as the new headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "xaQ3qR4msywy",
    "outputId": "aa50b74b-3234-44ec-f1ed-386b2ab16249"
   },
   "outputs": [],
   "source": [
    "# Combine headers into one (Ratsmitgliedes info)\n",
    "df_votings = pd.DataFrame(df_votings_raw.values[8:], columns=combined_headers)\n",
    "df_votings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votings.iloc[:5, :15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Redundant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnTSa4BFiyku"
   },
   "source": [
    " We drop the redundant columns `Ratsmitglied (Nr) | Name des Ratsmitgliedes | Rat | Fraktion | Kanton | Geburtsdatum | Vereidigungsdatum | Vereidigungsdatum` and `Rat` (which is `NR` for all items, as we only look at the national council). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FV8SXDSdshQk",
    "outputId": "28a9795e-c2cf-4b00-ee78-a78c8e13079c"
   },
   "outputs": [],
   "source": [
    "# Remove unused columns\n",
    "df_votings.drop(columns=['Ratsmitglied (Nr) | Name des Ratsmitgliedes | Rat | Fraktion | Kanton | Geburtsdatum | Vereidigungsdatum | Vereidigungsdatum',\n",
    "                        'Rat', 'Teilnahme Präsident/in an der Abstimmung'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Column Headers\n",
    "Next, we translate the column headers to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votings.rename(columns={\n",
    "    'Abstimmungsdatum': 'Voting Date', \n",
    "    'Zuständige Kommission': 'Responsible Commission',\n",
    "    'Zuständige Behörde': 'Responsible Authority',\n",
    "    'Geschäftsnummer': 'Topic Number',\n",
    "    'Geschäftstitel': 'Topic Title',\n",
    "    'Referenznummer': 'Reference ID',\n",
    "    'Bedeutung Ja': 'Meaning of Yes',\n",
    "    'Bedeutung Nein': 'Meaning of No',\n",
    "    'Abstimmungsgegenstand': 'Voting Subject',\n",
    "    'Vorlagetitel': 'Proposal Title'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we set the \"Referenznummer\" of the proposal as index, as it is unique for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votings.set_index('Reference ID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Adapt the above command to also translate the columns \"Entscheid des Rates\", \"Anzahl 'Ja'\", \"Anzahl 'Nein'\", \"Anzahl Enthaltungen\", \"Anzahl 'entschuldigt'\", \"Anzahl 'nicht teilgenommen'\" to \"Council Decision\", \"Number of Yes\", \"Number of No\", \"Number of Abstentions\", \"Number of excused\", \"Number of non-participation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUH-GVbDNMwN"
   },
   "source": [
    "## Overview of the Data\n",
    "To verify the data is in good shape, we look at the different colums:\n",
    "\n",
    "first 9 columns contain the proposal information:\n",
    "- Voting Date\n",
    "- Responsible Commission\n",
    "- Responsible Authority\n",
    "- Topic Number\n",
    "- Topic Title\n",
    "- Meaning of Yes\n",
    "- Meaning of No\n",
    "- Voting Proposal\n",
    "- Voting Title\n",
    "\n",
    "last 6 columns are summary of voting:\n",
    "- Council Decision\n",
    "- Number of Yes\n",
    "- Number of No\n",
    "- Number of Abstentions\n",
    "- Number of excused\n",
    "- Number of non-participation\n",
    "\n",
    "The columns in between the votes by the members of parliament:\n",
    "- 4049 | Aebischer, Matthias | NR | S | BE | 18.10.1967 | 04.12.2023 | 04.12.2023\n",
    "- 10803 | Aellen, Cyril | NR | RL | GE | 29.02.1972 | 04.12.2023 | 04.12.2023\n",
    "- \\...\n",
    "- 4179 | Zuberbühler, David | NR | V | AR | 20.02.1979 | 04.12.2023 | 04.12.2023\n",
    "- 10822 | Zybach, Ursula | NR | S | BE | 29.08.1967 | 04.12.2023 | 04.12.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify, we briefly look at each of these groups of columns and print the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_info_col_count = 9\n",
    "case_info_cols = list(df_votings.columns[:case_info_col_count])\n",
    "print(case_info_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_col_count = 6\n",
    "summary_cols = list(df_votings.columns[-summary_col_count:])\n",
    "print(summary_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are 200 members of parliament, one of them is the president. We only print the first and last few to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvPMEEV_XSRi"
   },
   "outputs": [],
   "source": [
    "senators_cols = list(df_votings.columns[case_info_col_count:-summary_col_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(senators_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkBieQYL0iix",
    "outputId": "57f99168-68af-42be-c169-31208a06cf47"
   },
   "outputs": [],
   "source": [
    "for mem in senators_cols[:3]:\n",
    "    print(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mem in senators_cols[-3:]:\n",
    "    print(mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7ANd2jBpP12"
   },
   "source": [
    "To check the data content, we print the unique text values in some important columns and will replace text values with numbers later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVv40dFJxv-7",
    "outputId": "6ab6b49b-e9c9-4580-f8b8-541eca994f85"
   },
   "outputs": [],
   "source": [
    "cols_to_transform_ja_nein = senators_cols + ['Council Decision']\n",
    "np.unique(df_votings.loc[:,cols_to_transform_ja_nein].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nDfV4_wrgD2",
    "outputId": "92bcf7fb-2364-4c51-997d-903dacfc0996"
   },
   "outputs": [],
   "source": [
    "df_votings['Responsible Commission'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jm5HANIKr1fN",
    "outputId": "4947d618-95d0-4b52-aa84-0162c30dc3ef"
   },
   "outputs": [],
   "source": [
    "df_votings['Responsible Authority'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLa6BTC6tcGL"
   },
   "source": [
    "Note that there are missing values in `Responsible Commission` and `Responsible Authority`. We fill them with `Unknown`, as we already have `Unknown` as another value. We first count how many records will be affected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votings[['Responsible Commission', 'Responsible Authority']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "tNXfPsn6tpIm",
    "outputId": "5e5073b6-be74-4dd4-ebd8-076d3a9d1905"
   },
   "outputs": [],
   "source": [
    "df_votings['Responsible Authority'] = df_votings['Responsible Authority'].fillna('Unknown')\n",
    "df_votings['Responsible Commission'] = df_votings['Responsible Commission'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agq7tMC3v7jh"
   },
   "source": [
    "## Data Transformation\n",
    "In order to process the data using different machine learning techniques, we need to process the actual values on our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving new Attributes\n",
    "One common step is to compute new attributes (or features). For example, we might want to know the percentage of members of parliament that voted 'Yes' to a given proposal:\n",
    "\n",
    "**Exercise:** Write code to compute the percent of `yes` votes, and store this information as a new column called `Percent_Yes` in the dataframe `df_votings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_votings['Percent_Yes'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdesvvXhiq7D"
   },
   "source": [
    "### Conversion to Numeric Values\n",
    "In the following cell we convert text to numbers.\n",
    "\n",
    "The possible values for votes are\n",
    "- Ja\n",
    "- Nein\n",
    "- Enthaltung\n",
    "- Hat nicht teilgenommen\n",
    "- Entschuldigt gem. Art. 57 Abs. 4\n",
    "- Die Präsidentin/der Präsident stimmt nicht\n",
    "\n",
    "We convert \"Ja\" (yes) and \"Nein\" (no) to 1 and -1, respectively. We map all different reasons for non-participantion to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziPshpfJwTQt"
   },
   "outputs": [],
   "source": [
    "df_nr_votings = df_votings.copy()\n",
    "mapping_ja_nein = {'Ja': 1, 'Nein': -1, 'Enthaltung': 0, 'Hat nicht teilgenommen': 0, \n",
    "                   'Entschuldigt gem. Art. 57 Abs. 4': 0,\n",
    "                   'Die Präsidentin/der Präsident stimmt nicht':0 }\n",
    "df_nr_votings.loc[:, cols_to_transform_ja_nein] = \\\n",
    "            df_nr_votings.loc[:, cols_to_transform_ja_nein].map(mapping_ja_nein.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhiVqqMqj6jE"
   },
   "source": [
    "Next we convert `Responsible Commission` and `Responsible Authority` to one-hot encodings. We can use the function `get_dummies` from the `pandas` library to do so. We start with the `Responsible Commission`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RC_OH_encoded = pd.get_dummies(df_nr_votings['Responsible Commission'],  dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at how the first row was transformed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_votings['Responsible Commission'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RC_OH_encoded.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we got many new columns, one for each unique value in the original column `df_nr_votings['Responsible Commission']`. In the first row, the resonsible commission was `' FK-NR | FK-SR | N/A-D-V | WBK-NR | WBK-SR'`. In the transformed dataframe, there is a 1 in the column corresponding to this commission, and all other columns are set to 0. This is why this type of representing categorical attributes is called *one-hot encoding*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the `'Responsible Authority'`.\n",
    "\n",
    "**Exercise:** Convert `'Responsible Authority'` to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_RA_OH_encoded = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine the original dataframe with the two newly created dataframes containing the one-hot encodings.\n",
    "\n",
    "**Exercise:** Write code to combine the three dataframes into a single dataframe called `df_nr_votings`. Since we have replaced the two columns `'Responsible Commission'` and `'Responsible Authority'`, by one-hot encodings, we also want to drop the two original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nr_votings = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "DR-mpQ1pruWb",
    "outputId": "45c740c4-4351-4172-8bd6-70ba86a89fda"
   },
   "outputs": [],
   "source": [
    "df_nr_votings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlolauVN-cK6"
   },
   "source": [
    "### Handling Missing Values\n",
    "Finally, we have to check whether there are any missing values. \n",
    "\n",
    "Missing values are typically indicated as `NA`. However, some missing values might also be more difficult to find, as they might be encoded in a different way. In our dataframe, there are some records where the `Topic Number` is set to `'Unknown'`.\n",
    "\n",
    "**Exercise:** Implement the following steps to get rid of missing values:\n",
    "* Count the total number of `na` values. Remember that you can use the functions `isna()` in any dataframe to find out, for every cell of the dataframe, whether the corresponding value is `NA` or not. Furthermore, you can use the function `df.sum()` to sum over the first dimension of a dataframe `df`.\n",
    "* Delete all records (rows) which contain a `NA` value.\n",
    "* Identify (e.g., print out) the records that have an `Unknown` `Topic Number`. Decide on what to do with these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Text Data\n",
    "Some of the columns contain text data. We will vectorize these texts using count vectorizers to get a representation that we will use afterwards.\n",
    "\n",
    "The following block of code runs a joint `CountVectorizer` for the `text_columns`. Using a `for` loop, it then iterates over the columns and does a vectorization. \n",
    "* In the first line of the `for` loop, the count vectorizer is used to transform the data. This yields a matrix (`transformed_data`) where each row corresponds to a voting proposal, and each column corresponds to the number of times the respective word occurrs in that text column.\n",
    "* In the second column, a `DataFrame` is generated from the matrix `transformed_data`, with the column name representing first the name of the column of the original data frame, and then, separated by a `_`, the word that is counted in the respective column of the output dataframe.\n",
    "* Finally, in the third line of the `for` loop, the new data frame is combined with the previously generated text representations in `df_nr_vectorized_text_info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns that contain text\n",
    "text_columns = ['Topic Title', 'Meaning of Yes', 'Meaning of No', 'Voting Subject', 'Proposal Title']\n",
    "\n",
    "df_nr_vectorized_text_info = pd.DataFrame({})\n",
    "\n",
    "# Transform each text column using CountVectorizer\n",
    "for col in text_columns:\n",
    "    # Initialize CountVectorizer\n",
    "    vectorizer = CountVectorizer(max_features=50)\n",
    "    # adapt the vectorizer to the dataset (i.e., the column we are currently considering\n",
    "    transformed_data = vectorizer.fit_transform(df_nr_votings[col])\n",
    "    # convert the data to an understandable dataframe\n",
    "    transformed_df = pd.DataFrame(transformed_data.toarray(), columns=[f\"{col}_{word}\" for word in vectorizer.get_feature_names_out()], \n",
    "                                 index=df_nr_votings.index)\n",
    "    df_nr_vectorized_text_info = pd.concat([df_nr_vectorized_text_info, transformed_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df_nr_vectorized_text_info` now contains all the proposals as rows, and all the information of the text columns as columns.\n",
    "\n",
    "**Exercise:** While the technical aspect of the above code cell is nontrivial (but also not needed for the rest of the project), it's important you understand the result of this. Take a moment to understand the representation we have generated. For example, look at `df_nr_vectorized_text_info` or the intermediate results in `transformed_data` and `transformed_df`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Exercise**: In the above cell, we have not used any stop-words. When looking at `df_nr_vectorized_text_info`, you will find both very common words and numbers being counted (and the counts being represented in the columns of `df_nr_vectorized_text_info`). \n",
    "\n",
    "Processing text data is often tricky and can be tedious, but also can have a significant impact on the performance. Play around with the preprocessing, e.g. with the following modifications (and combinations thereof):\n",
    "* `CountVectorizer()` takes an optional argument `stop_words` and a list of words to be ignored (typically, because they are considered very common and thus uninformative). For example, you can write `vectorizer = CountVectorizer(stop_words = ['der', 'die', 'das'])`. Add your own stopwords, or find a list of common words in German (unfortunately, `scikit-learn` has a predefined list of stopwords only for English).\n",
    "* You can replace any number by `NUM` by replacing `df_nr_votings[col]` (in the first line of the `for` loop) by `df_nr_votings[col].replace('\\d+', 'NUM', regex=True)`; the vectorizer will then only see `NUM` instead of any number. Alternatively, you can use `df_nr_votings[col].replace('\\d+', '', regex=True)` to remove any number in the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make make a copy of the original `df_nr_votings` dataframe where we remove the text columns. We save this as `df_nr_votings_numeric`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_votings_numeric = df_nr_votings.copy().drop(columns=text_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data frame `df_nr_votings_numeric`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_votings_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains two columns with general information, then the cast votes of every member of parliament (one column for each of the 200 members), and then some more information about the proposal. To avoid confusion, we separate the cast votes from the information about the subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_cast_votes = df_nr_votings_numeric.copy().iloc[:, 2:202]\n",
    "df_nr_numeric_info = df_nr_votings_numeric.drop(columns=df_nr_cast_votes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_nr_numeric_info` still contains a column `Voting Date`, which is not numeric, and which we will not use in our analysis. We therefore drop it as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_numeric_info.drop(columns='Voting Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "To summarize, we now have the following three dataframes:\n",
    "* `df_nr_numeric_info`: Numeric information about the voting proposals, e.g., the responsible administration.\n",
    "* `df_nr_vectorized_text_info`: vectorized text information about the voting proposals.\n",
    "* `df_nr_cast_votes`: the votes by each member of parliament (each column corresponds to a member of parliament).\n",
    "In all 3 dataframes, each line is one voting proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_numeric_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_vectorized_text_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_cast_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as we will train some models using all available data (i.e., the numerical and the text data), we combine `df_nr_numeric_info` and `df_nr_vectorized_text_info` to `df_nr_all_info`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_all_info = pd.concat([df_nr_numeric_info, df_nr_vectorized_text_info], axis=1)\n",
    "df_nr_all_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_all_info.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKLZR7Ya_rAA"
   },
   "source": [
    "## Save the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbw63hPpmkj4"
   },
   "source": [
    "Finally we are ready to save the dataframes into files that we will load when running  other analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_numeric_info.to_csv(file_path.replace('.xlsx', '_numeric_info.csv'))\n",
    "df_nr_vectorized_text_info.to_csv(file_path.replace('.xlsx', '_vectorized_text_info.csv'))\n",
    "df_nr_cast_votes.to_csv(file_path.replace('.xlsx', '_cast_votes.csv'))\n",
    "df_nr_all_info.to_csv(file_path.replace('.xlsx', '_all_info.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, for later reference, we save a brief summary for every voting proposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = [ x for x in (case_info_cols + summary_cols + ['Percent_Yes']) if not x in ['Responsible Commission', 'Responsible Authority'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_votings[ info_cols ].to_csv(file_path.replace('.xlsx', '_summary.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "* Given the dataset that we have now cleaned, what applications could you imagine? How could they be useful?\n",
    "* What other data might be useful? What additional analysis could you do with additional data?\n",
    "\n",
    "Discuss your ideas with another participant or somebody from the teaching team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
