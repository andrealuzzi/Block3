{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Data Science & Machine Learning on Votings of the Swiss National Council\n",
    "\n",
    "In project 5, we will analyze the voting behavior of the \"Nationalrat\" of the Swiss parliament in a number of ways. The project consists of 3 different files:\n",
    "\n",
    "* Data Preparation: Prepare the data for the other two notebooks.\n",
    "* Voting Predictions (this notebook): Predict the voting behavior of individual members or the entire council.\n",
    "* Unsupervised: Find lower-dimensional representations of the voting behavior and groups of members of parliament.\n",
    "\n",
    "**Make sure to have run the data preparation notebook before running this one!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "We start with the usual preparations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b9NNIoL7c8d",
    "outputId": "8f76b276-d3c5-4e57-d62b-3cefc1f32a7d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re # regular expressions\n",
    "from datetime import datetime # to calculate the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPQ-e3SR7_VL"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpxebOQa8JHf"
   },
   "source": [
    "First, we load the processed data sets. To see the detailed data preprocessing, please refer to Project 5 - Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycfCfQZdsYfa"
   },
   "outputs": [],
   "source": [
    "file_path_ss24_nr_root = 'Abstimmungen_NR_2024SS_DE'\n",
    "\n",
    "df_nr_numeric_info = pd.read_csv(file_path_ss24_nr_root + '_numeric_info.csv', index_col='Reference ID')\n",
    "df_nr_vectorized_text_info = pd.read_csv(file_path_ss24_nr_root + '_vectorized_text_info.csv', index_col='Reference ID')\n",
    "df_nr_all_info = pd.read_csv(file_path_ss24_nr_root + '_all_info.csv', index_col='Reference ID')\n",
    "df_nr_cast_votes = pd.read_csv(file_path_ss24_nr_root + '_cast_votes.csv', index_col='Reference ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_numeric_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_all_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_cast_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Individual Voting Behavior\n",
    "We will now try to predict the voting behavior per member of parliament. To start, we will choose one member, and train a classifier for that person based on the available information of the proposal. Later on, we will build a classifier to predict the voting behavior of every person based on the characteristics of that person and on the available information of the proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5IGk6RU9vUg"
   },
   "source": [
    "## Building a Member-Specific Classifier\n",
    "We use the first member in the table as an example, and train a model to predict the voting behavior of that person. For no particular reason, we choose the member with index 0. You can of course try with any other member of parliament.\n",
    "\n",
    "The cast votes of that person will be the target value we try to predict, which is typically denoted by `y`. We therefore call this target variable `Y_selected_member`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "BUurNl7C91t9",
    "outputId": "21b19dfe-efc7-4068-e943-cfc1ce771968"
   },
   "outputs": [],
   "source": [
    "Y_selected_member = pd.DataFrame(df_nr_cast_votes.iloc[:,0])\n",
    "Y_selected_member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will try to predict these values first based only on the text columns (i.e. using the vectorized text data), and later also using the additional information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8iDyT5NWeYx"
   },
   "source": [
    "### Prediction based only on Text Columns\n",
    "We first have to prepare the data such that we can train and evaluate the model. Therefore, we go through a typical machine learning pipeline:\n",
    "- Split the dataset\n",
    "- Train the model\n",
    "- Evaluate the model\n",
    "\n",
    "When splitting the dataset, we use the simplest way: randomly choose 20% of the whole dataset to be the test dataset. The splitting could be done in a more refined way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Exercise:** What are the implications of this way of splitting the data? What alternatives could we use, with what benefits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, to simplify things a bit, we will only consider proposals where the selected proposal did vote yes or no, and will ignore cases of abstention or absence.\n",
    "\n",
    "Technical note: `Y_selected_member` is a data frame. The comparison `Y_selected_member!= 0` will again yield a data frame. In order to use the corresponding `True` and `False` values, we have to extract the `values` to get an array we can then use for logical indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_where_selected_member_voted = (Y_selected_member!= 0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the prediction will be done based on `df_nr_vectorized_text_info`. For both the features and the target value, we have to choose only the rows (proposals) where the selected member voted.\n",
    "\n",
    "We use the well-known function `train_test_split` to get the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlcA1UTTANfX",
    "outputId": "539c1f82-a349-46ce-ba93-37ee06b34d9c"
   },
   "outputs": [],
   "source": [
    "# We split the dataset into training and test dataset.\n",
    "X_selected_member_train, X_selected_member_test, Y_selected_member_train, Y_selected_member_test = \\\n",
    "  train_test_split(df_nr_vectorized_text_info[proposals_where_selected_member_voted],\n",
    "                   Y_selected_member[proposals_where_selected_member_voted],\n",
    "                   test_size=0.2,\n",
    "                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "**Exercise:** Train a logistic regression model, and evaluate it. Comment on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Train and Evaluate Classifiers\n",
    "As we will be evaluating several classifiers, we define a function to train and evaluate a model. It is very similar to the cell above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_apply_eval_model_classification(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train a given model on a training data set, and evaluate it on both the training and test data.\n",
    "\n",
    "    Arguments:\n",
    "    - model: the model to be evaluated\n",
    "    - X_train: the training predictors\n",
    "    - y_train: the true labels of the training data set\n",
    "    - X_test: the predictors of the test data set\n",
    "    - y_test: the true labels of the test data set\n",
    "    \"\"\"\n",
    "\n",
    "    # If we are entering a dataframe as target values, we get a warning.\n",
    "    # The line below fixes this.\n",
    "    \n",
    "    # Train the model:\n",
    "    if isinstance(y_train, pd.DataFrame):\n",
    "        model.fit(X_train, y_train.values.squeeze())\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    report = classification_report(y_test, y_pred_test)\n",
    "    \n",
    "    print(f'Accuracy Train: {accuracy_train}')\n",
    "    print(f'Accuracy Test: {accuracy_test}')\n",
    "    print(f\"\\nClassification Report (Test data):\\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvmhhIxuA07i"
   },
   "source": [
    "### Predictions based on all Columns\n",
    "Next, we will use all information (i.e., both the numerical and the text data) of the voting proposal to predict the voting behavior of our selected member of parliament. We already have this stored in the variable `df_nr_all_info`. As above, we need to make sure that we only use voting proposals where the selected person did vote either \"yes\" or \"no\".\n",
    "\n",
    "**Exercise:** split the full data `into X_selected_member_train`, `X_selected_member_test`, `Y_selected_member_train`, `Y_selected_member_test` using `train_test_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_selected_member_train, X_selected_member_test, Y_selected_member_train, Y_selected_member_test = \\\n",
    "#   train_test_split( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "na6dsqcFBU3k"
   },
   "source": [
    "#### Logistic Regression\n",
    "Again, we will run a logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "train_apply_eval_model_classification(logistic_regression, X_selected_member_train, Y_selected_member_train, \n",
    "                                      X_selected_member_test, Y_selected_member_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Comment on the above results. In particular, do you think we should add a regularisation (e.g., LASSO)? Or would you recommend another way to improve the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Implement a way to improve the results of the logistic regression classifier (but stay with this technique for now)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we get the coefficients of each of the attributes, and we sort the attributes along the coefficient value. \n",
    "\n",
    "We also compute the ***Odds Ratio***, which is another way to quantify probabilities. If we choose a random day, the chances are 2/7 (or 28.57%) that this day will be a weekend day, and 5/7 that it will be a work day. Here, 2/7 and 5/7 are the **probabilities** of the two events (i.e., the event that the chosen day is a weekend day, or a work day, respectively). In terms of **odds**, one would say that the **odds ratio** is 2 to 5 for a weekend day (because there are 2 events that would make the chosen day a weekend day (namely, 'the chosen day is a Saturday', and 'the chosen day is a Sunday'), and 5 events that make the chosen day a working day (namely, 'the chosen day is a Monday', ..., 'the chosen day is a Friday'), and all these events are considered equally probable (as we have chosen the day at random). Sometimes, the odds ratio is also expressed as a probability, i.e. the odds ratio for a weekend day is 40% (2/5).\n",
    "\n",
    "We then print the resulting data frame to see the attributes that are most and least in favor of a 1 (i.e., a vote YES):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients\n",
    "coefficients = logistic_regression.coef_[0]  # model.coef_ is a 2D array; [0] gets the coefficients for the first class if binary\n",
    "\n",
    "# Get the intercept (bias term)\n",
    "intercept = logistic_regression.intercept_[0]\n",
    "\n",
    "feature_names = X_selected_member_train.columns\n",
    "\n",
    "# Create a DataFrame to display the coefficients with feature names\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "coeff_df['Odds_Ratio'] = np.exp(coeff_df['Coefficient'])\n",
    "\n",
    "# Sort the coefficients by their absolute value to see which features are most influential\n",
    "coeff_df = coeff_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(coeff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Interprete these results, and discuss possible limitiations of this interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Overfitting\n",
    "**Exercise:** Modify the logistic regression code above to reduce overfitting. To do so, look at regularization methods. Note that for `LogisticRegression`, you might have to specify the solver. In particular, if you want to use logistic regression with an `l1` penalty, call\n",
    "\n",
    "`LogisticRegression(penalty='l1', solver='liblinear')`\n",
    "\n",
    "For more information, check https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Aa738aoCbdJ"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "train_apply_eval_model_classification(random_forest, X_selected_member_train, Y_selected_member_train, \n",
    "                                      X_selected_member_test, Y_selected_member_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Comment on the above results. In particular, do you think we should add a regularisation? Or would you recommend another way to improve the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Exercise:** Implement your recommended way to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "As9ypSd0Cv-a"
   },
   "source": [
    "## Building a Classifier for All Members of Parliament\n",
    "\n",
    "Next, we will use the information available about the members of the parliamant in order to predict their voting behavior. While we will use the same information about the proposals as above, we will use the information about the members of parliament to try to predict a given persons' cast votes. In particular, the information we use about the members of parliaments are the *parliamentary group* (*Fraktion* in German), the *canton* the person represents, and the age (which we derive from the date of birth).\n",
    "\n",
    "### Data Preparation\n",
    "The below cells do this transformation. The details are rather technical and not necessary for the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FelSoXhQC0hg",
    "outputId": "ebcce11a-bfb9-40ea-ce8b-1188970a9506"
   },
   "outputs": [],
   "source": [
    "Y_all_members_reset = df_nr_cast_votes.reset_index()\n",
    "\n",
    "# create long format of data\n",
    "Y_long_with_MPinfo = pd.melt(Y_all_members_reset, id_vars=['Reference ID'], \n",
    "                             var_name='Person', value_name='Vote')\n",
    "\n",
    "# extract information about members in separate columns\n",
    "person_split = Y_long_with_MPinfo['Person'].str.split('|', expand=True)\n",
    "Y_long_with_MPinfo[['Person ID', 'Name', 'Chamber', 'Parl_Group', 'Canton', 'Birthday', 'Swear-in date 1',\n",
    "                    'Swear-in date 2']] = person_split.apply(lambda x: x.str.strip())\n",
    "\n",
    "Y_long_with_MPinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "M8hL6OajDFjE",
    "outputId": "59ac67d7-1515-4b03-a108-4526eee8c8e9"
   },
   "outputs": [],
   "source": [
    "# transform the column \"Birthday\" to datetime format\n",
    "Y_long_with_MPinfo['Birthday'] = pd.to_datetime(Y_long_with_MPinfo['Birthday'], format='%d.%m.%Y', dayfirst=True)\n",
    "\n",
    "# Calculate age of member in current session\n",
    "today = datetime.today()\n",
    "Y_long_with_MPinfo['Age'] = Y_long_with_MPinfo['Birthday'].apply(lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)))\n",
    "\n",
    "# Now we can drop the original \"Person\" column and other columns we don't need\n",
    "Y_long_with_MPinfo.drop(columns=['Person', 'Name', 'Chamber', 'Birthday', 'Swear-in date 1', 'Swear-in date 2'], inplace=True)\n",
    "Y_long_with_MPinfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a table that contains the vote, the fraction, the represented canton and the age of every member of parliament, and for every voting proposal (`Reference ID`).\n",
    "\n",
    "Next, we need to transform the categorical attributes `Parl_Group` and `Canton` into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_long_with_MPinfo_dummy = pd.get_dummies(Y_long_with_MPinfo, columns=['Parl_Group', 'Canton'], prefix=['PG', 'Canton']).astype(int)\n",
    "Y_long_with_MPinfo_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can combine `Y_long_with_MPinfo_dummy` with `df_nr_all_info` in order to get a table that contains all the information of the proposal, and all the information about the person, for every proposal and every person that voted yes or no. Note that this is a highly redundant data representation that is optimized for our prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nr_all_info_wMPinfo = pd.merge(Y_long_with_MPinfo_dummy, df_nr_all_info, left_on='Reference ID', right_on='Reference ID', how='left')\n",
    "df_nr_all_info_wMPinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop all rows that have a label = 0, which indicates that the member did not vote\n",
    "rows_without_zero_label = (df_nr_all_info_wMPinfo['Vote'] != 0)\n",
    "df_nr_all_info_wMPinfo = df_nr_all_info_wMPinfo[rows_without_zero_label]\n",
    "df_nr_all_info_wMPinfo['Vote'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YmqkHQoE3Af"
   },
   "source": [
    "Next, we have to split our data into training and test data. \n",
    "\n",
    "**Exercise:** What could be different criteria, or different ways to do the splitting in this scenario? For each of the ways to split the data, what would be an application case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data along the members of parliament, i.e., 20% of the persons will be selected, and all their votes will be used for the test dataset. All the remaining people and their votes are used as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evTNH6WCE0Rz"
   },
   "outputs": [],
   "source": [
    "unique_member_ids = df_nr_all_info_wMPinfo['Person ID'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_member_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "df_nr_all_info_wMPinfo_train = df_nr_all_info_wMPinfo[df_nr_all_info_wMPinfo['Person ID'].isin(train_ids)]\n",
    "df_nr_all_info_wMPinfo_test  = df_nr_all_info_wMPinfo[df_nr_all_info_wMPinfo['Person ID'].isin(test_ids)]\n",
    "\n",
    "X_nr_all_info_wMPinfo_train = df_nr_all_info_wMPinfo_train.drop(columns=['Vote'])\n",
    "y_nr_all_info_wMPinfo_train = df_nr_all_info_wMPinfo_train['Vote']\n",
    "\n",
    "X_nr_all_info_wMPinfo_test = df_nr_all_info_wMPinfo_test.drop(columns=['Vote'])\n",
    "y_nr_all_info_wMPinfo_test = df_nr_all_info_wMPinfo_test['Vote']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58A6zR8OFOlR"
   },
   "source": [
    "Now we are ready to train different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc1VQJJjFUnD"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty=None, random_state=42, max_iter=1000)\n",
    "\n",
    "train_apply_eval_model_classification(logistic_regression, X_nr_all_info_wMPinfo_train, y_nr_all_info_wMPinfo_train, \n",
    "                                      X_nr_all_info_wMPinfo_test, y_nr_all_info_wMPinfo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How could we improve the performance of this model? \n",
    "\n",
    "*Hint:* You might want to check the scale of the inputs to the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Apply at least one other classification technique, and discuss the results in comparison to the result obtained using logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7aEOgqemuVw"
   },
   "source": [
    "# Regression\n",
    "\n",
    "In this part, we are doing regression to predict the acceptance ratio of a given subject.\n",
    "\n",
    "The target value is `Percent_Yes` in the dataframe `df_nr_all_info`; i.e. we will use all the available information about the proposal being voted on. We will not use any information about the members of parliament, because we only consider data from one session (Summer 2024), so the members of parliament do not change, and we discard the information about who participated in the vote.\n",
    "\n",
    "* Try (define, train and evaluate) different regression methods\n",
    "* Logistic regression might be an interesting option, as it yields a prediction result that fits into the target range 0...1 (0-100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "We will derive the features and target value from `df_nr_all_info`.\n",
    "\n",
    "* The target value, as already mentioned, is `df_nr_all_info['Percent_Yes']`.\n",
    "* The features used are all other features of `df_nr_all_info` except `Percent_Yes`, and some features that are closely related to it, such as the number of yes and no votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_overall_4reg = df_nr_all_info['Percent_Yes']\n",
    "Y_overall_4reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_overall_4reg = df_nr_all_info.drop(columns=['Percent_Yes'])\n",
    "\n",
    "X_overall_4reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data into a training and test set. This split is done independently for each proposal, which is somewhat a simplification of the actual political process, as some proposals might depend on each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02h9aRNBd7ZN"
   },
   "outputs": [],
   "source": [
    "X_overall_4reg_train, X_overall_4reg_test, Y_overall_4reg_train, Y_overall_4reg_test = \\\n",
    "    train_test_split(X_overall_4reg, Y_overall_4reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Regression Methods\n",
    "In this section, we will compare different regression models.\n",
    "\n",
    "* Given that we are predicting a continuous variable, linear regression seems to be the default starting point.\n",
    "* As we are predicting a value between 0 and 1, the idea of logistic regression might sound appealing, as this would directly ensure that the output values are between 0 and 1.\n",
    "* Finally, we try a more complex neural network to evaluate the performance of a model with higher degree of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Model Training and Evaluation\n",
    "As we will evaluate several models, we again define a function to summarize these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_apply_eval_model_regression(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train a given model on a training data set, and evaluate it on both the training and test data.\n",
    "\n",
    "    Arguments:\n",
    "    - model: the model to be evaluated\n",
    "    - X_train: the training predictors\n",
    "    - y_train: the true labels of the training data set\n",
    "    - X_test: the predictors of the test data set\n",
    "    - y_test: the true labels of the test data set\n",
    "    \"\"\"\n",
    "\n",
    "    # if we have a neural network model, we first have to compile the model, and the fitting method needs more arguments.\n",
    "    if 'keras' in str(type(model)) and 'Sequential' in str(type(model)):\n",
    "        # Compile the model. This means to combine necessary components together. You must compile it before start training.\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mean_squared_error', 'r2_score']\n",
    "            )\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=20,\n",
    "            batch_size=16,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # we can just call 'fit' to train the model:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaludate the model\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f'MAE Train: {mae_train}')\n",
    "    print(f'MAE Test: {mae_test}')    \n",
    "    print(f'R2 Train: {r2_train}')\n",
    "    print(f'R2 Test: {r2_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to evaluate the performance of different regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3_g1h5iSwVl"
   },
   "source": [
    "### Linear Regression\n",
    "As a first trial, we run a linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "\n",
    "train_apply_eval_model_regression(linear_regression, X_overall_4reg_train, Y_overall_4reg_train, X_overall_4reg_test, Y_overall_4reg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "\n",
    "Comment on the results of the above cell. \n",
    "\n",
    "*Hint*: If you think it looks too good to be true, you are on the right track ;-) Can you spot the issue?\n",
    "\n",
    "Fix the issue you spotted above, and re-run the regression. Comment on the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "How can you improve the performance of the linear regression? Use the techniques discussed in the course to do so, and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Exercises:**\n",
    "\n",
    "Propose and implement one possible improvement over the standard linear regression. Identify a shortcoming of the solution of the linear regression above, and argue why / how your improvement could address it. Double-check your expectation with the result.\n",
    "\n",
    "Two hints and ideas:\n",
    "\n",
    "* We have introduced random forest classifiers in class. Random forests can also be used for regression, and `scikit-learn` provides a class `RandomForestRegressor` with the usual functions (`fit(...)`, `predict(...)`) that you know from other methods. For details, check https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "* (Advanced): The outputs are in a clearly defined range, but linear regression does not make use of this information. In `scikit-learn`, there is no function to take this information into account. However, you can build a neural network to do so. Start with a neural network for linear regression, and then extend this one. Experiment with different network architectures (number of layers, number of neurons, regularization) to find a good model. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
